{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Initializiton ####\n",
    "rm(list = ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "\n",
    "library(lhs)  # For maximin Latin hypercube sampling\n",
    "library(ggplot2)\n",
    "library(plotly)  # For beautiful plotting\n",
    "library(caret)\n",
    "library(randomForest)\n",
    "library(factoextra)\n",
    "library(e1071)\n",
    "library(TSrepr)  # for evaluating predictive power\n",
    "\n",
    "require(gridExtra)\n",
    "\n",
    "options(warn = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### functions ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_entry <- function(){\n",
    "    write(paste0( \"model =\",nl.model,\"\\n\"\n",
    "             ,\"nofrep =\",nofrep,\"\\n\"\n",
    "             ,paste0(c(\"metarep =\",metarep),collapse = \" \"),\"\\n\"\n",
    "             ,\"ntree =\",ntree,\"\\n\"\n",
    "             ,\"mtry =\",mtry,\"\\n\"\n",
    "             ,\"nperm =\",nperm,\"\\n\"\n",
    "             ,\"iteration_budget =\",iteration_budget,\"\\n\"\n",
    "             ,\"unlabeled_ins =\",unlabeled_ins,\"\\n\"\n",
    "             ,\"unlabeled.type =\",unlabeled.type,\"\\n\"\n",
    "             ,paste0(c(\"test_ins =\",test_ins),collapse = \" \"),\"\\n\"\n",
    "             ,\"train_ins_Ad =\",train_ins_Ad,\"\\n\"\n",
    "             ,\"selected_ins =\",selected_ins,\"\\n\"\n",
    "             ,\"h =\",h,\"\\n\"\n",
    "             ,paste0(c(\"seed.focus =\",seed.focus),collapse = \" \"),\"\\n\"             \n",
    "             ,\"error_type =\",error_type,\"\\n\" \n",
    "             ,\"sample.type =\",sample.type,\"\\n\"\n",
    "             ,\"selection_metric =\",selection_metric,\"\\n\" \n",
    "             ,\"Date =\", Sys.Date()\n",
    "             )\n",
    "      ,ReadMe, append=TRUE, sep = \"\\n\" )   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_model <- function(feature_names,feature_values){ # both should be in character list format both should be in character list format\n",
    "run_model <- function(feature_values) {\n",
    "    k = length(feature_names)\n",
    "    for (i in 1:k) {\n",
    "        NLCommand(paste0(\"set \", feature_names[i], \" \", feature_values[i]), nl.obj = nl.model)\n",
    "    }\n",
    "    NLCommand(\"setup\", nl.obj = nl.model)\n",
    "    NLDoCommand(100, \"go\", nl.obj = nl.model)\n",
    "    result <- NLReport(output_name, nl.obj = nl.model)\n",
    "    return(result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_replicas <- function(nofrep,feature_names,feature_values) {\n",
    "run_replicas <- function(nofrep, feature_values) {\n",
    "    replicas = matrix(NA, ncol = nofrep, nrow = 1)  # Save the result of each replication\n",
    "    for (i in 1:nofrep) {\n",
    "        # replicas[i]= run_model(feature_names,feature_values)\n",
    "        replicas[i] = run_model(feature_values)\n",
    "    }\n",
    "    aggregated_result = mean(replicas)\n",
    "    return(aggregated_result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run_ABM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_ABM = function(nofrep,nofinstances,unlabeledset,featurenames = feature_names){\n",
    "run_ABM = function(nofrep, nofinstances, unlabeledset) {\n",
    "    # unlabeledset = setcolorder(unlabeledset,featurenames)\n",
    "    unlabeledset = setcolorder(unlabeledset, feature_names)\n",
    "    for (i in 1:nofinstances) {\n",
    "        # unlabeledset[i, output := run_replicas(nofrep,featurenames,\n",
    "        # as.matrix(unlabeledset[i,]))]\n",
    "        unlabeledset[i, `:=`(output, run_replicas(nofrep, as.matrix(unlabeledset[i,])))]\n",
    "    }\n",
    "    return(unlabeledset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error functions on test data\n",
    "rmse_func <- function(actual, predicted) {\n",
    "    error = predicted - actual\n",
    "    return(sqrt(mean(error^2)))\n",
    "}\n",
    "\n",
    "mape_func <- function(actual, predicted) {\n",
    "    return((abs(actual - predicted)/actual) * 100)\n",
    "}\n",
    "\n",
    "bias_func <- function(actual, predicted) {\n",
    "    return((actual - predicted)/actual)\n",
    "}\n",
    "\n",
    "# error functions on train data\n",
    "obb_error_func <- function(model) {\n",
    "    if (model$type == \"regression\") {\n",
    "        oob_error = model$mse[model$ntree]\n",
    "    } else if (model$type == \"classification\") {\n",
    "        oob_error = model$err.rate\n",
    "    }\n",
    "    return(oob_error)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction functions\n",
    "get_test_predictions <- function(model, testset, errortype) {\n",
    "    \n",
    "    predictedLabels <- predict(model, testset)\n",
    "    predictedLabels <- cbind(testset, predictedLabels)\n",
    "    setnames(predictedLabels, \"predictedLabels\", \"pred_output\")\n",
    "    \n",
    "    output_variables = colnames(select(predictedLabels, contains(\"output\")))\n",
    "    # output_variables[1] = true output output_variables[2] = predicted output\n",
    "    \n",
    "    # output_variables = colnames(predictedLabels[,1:(ncol(predictedLabels) - 2)])\n",
    "    \n",
    "    if (error_type == \"MAPE\") {\n",
    "        predictedLabels[, `:=`(MAPE, mapply(function(x, y) mape_func(x, y), get(output_variables[1]), \n",
    "            get(output_variables[2])))]\n",
    "    }\n",
    "    if (error_type == \"RMSE\") {\n",
    "        predictedLabels[, `:=`(RMSE, mapply(function(x, y) rmse_func(x, y), get(output_variables[1]), \n",
    "            get(output_variables[2])))]\n",
    "    }\n",
    "    if (error_type == \"BIAS\") {\n",
    "        predictedLabels[, `:=`(BIAS, mapply(function(x, y) bias_func(x, y), get(output_variables[1]), \n",
    "            get(output_variables[2])))]\n",
    "    }\n",
    "    \n",
    "    output_variables_1 = predictedLabels[, get(output_variables[1]), with = TRUE]\n",
    "    output_variables_2 = predictedLabels[, get(output_variables[2]), with = TRUE]\n",
    "    \n",
    "    performance_temp = matrix(c(1:3), nrow = 1, ncol = 3)\n",
    "    performance_temp[1] = mae(output_variables_1, output_variables_2)\n",
    "    performance_temp[2] = rmse(output_variables_1, output_variables_2)\n",
    "    performance_temp[3] = mape(output_variables_1, output_variables_2)\n",
    "    \n",
    "    return(list(predictedLabels, performance_temp, output_variables))\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive sample selection function with an uncertainty measure depending on 'selection_metric'\n",
    "sample_selection <- function(selected_ins, unlabeled_set, model) {\n",
    "    ind_pred <- t(predict(model, unlabeled_set, predict.all = TRUE)$individual) %>% \n",
    "        data.table()  # predictions by each tree in the forest\n",
    "    ind_pred_eval = data.table()\n",
    "    \n",
    "    # standard deviation calculation\n",
    "    s_dev = sapply(ind_pred, sd) %>% data.table()\n",
    "    setnames(s_dev, \".\", \"sd\")\n",
    "    ind_pred_eval = cbind(ind_pred_eval, s_dev)\n",
    "    \n",
    "    # range calculation\n",
    "    range = sapply(ind_pred, range) %>% t() %>% data.table()\n",
    "    range = range[, .(range = abs(range[, 1] - range[, 2]))]\n",
    "    setnames(range, \"range.V1\", \"range\")\n",
    "    ind_pred_eval = cbind(ind_pred_eval, range)\n",
    "    \n",
    "    #coeff variance calculation\n",
    "    s_dev = sapply(ind_pred, sd) %>% data.table()\n",
    "    setnames(s_dev, \".\", \"sd\")\n",
    "    s_mean = sapply(ind_pred, mean) %>% data.table()\n",
    "    setnames(s_mean, \".\", \"mean\")\n",
    "    coeff_var = cbind(s_dev,s_mean) \n",
    "    coeff_var = coeff_var[,.(c_var = (sd / mean)* 100)]\n",
    "    ind_pred_eval = cbind(ind_pred_eval, coeff_var)\n",
    "    \n",
    "    ind_pred_eval[, `:=`(idx, 1:.N)]\n",
    "    \n",
    "    if (selection_metric == \"sd\") {\n",
    "        ind_pred_eval = ind_pred_eval[order(-sd)][1:selected_ins]\n",
    "    } else if (selection_metric == \"range\") {\n",
    "        ind_pred_eval = ind_pred_eval[order(-range)][1:selected_ins]\n",
    "    } else if (selection_metric == \"coefvar\") {\n",
    "        ind_pred_eval = ind_pred_eval[order(-coeff_var)][1:selected_ins]\n",
    "    }\n",
    "    \n",
    "    unlabeled_set[, `:=`(idx, 1:.N)]\n",
    "    train_candidates = unlabeled_set[ind_pred_eval$idx]\n",
    "    \n",
    "    return(train_candidates)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_sample_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample selection\n",
    "random_sample_selection <- function(selected_ins, unlabeled_set) {\n",
    "    \n",
    "    unlabeled_set[, `:=`(idx, 1:.N)]\n",
    "    \n",
    "    train_candidate_idx = sample(unlabeled_set$idx, selected_ins, replace = FALSE, prob = NULL)\n",
    "    train_candidates = unlabeled_set[idx %in% train_candidate_idx]\n",
    "    \n",
    "    return(train_candidates)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_variable_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_variable_importance <- function(model) {\n",
    "    importances <- importance(model, type = 1, scale = FALSE)\n",
    "    selected.vars <- order(importances, decreasing = TRUE)\n",
    "    ranked_features = feature_names[selected.vars]\n",
    "    ordered.importances <- importances[selected.vars]\n",
    "    \n",
    "    return(ranked_features)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_importance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ##unique to each seed and rep, updated iter by iter\n",
    "get_importance_data = function(model,type,scaled,n){\n",
    "    #n shows how many iterations' values will be evaluated (moving average n)\n",
    "    iteration_imp = data.table(t(importance(model, type = type, scaled = scaled))) %>% melt()\n",
    "    setnames(iteration_imp,\"variable\",\"feature\")\n",
    "    \n",
    "    imp_history = if(nrow(importance_data) > 0){\n",
    "        copy(importance_data[iter_no >= 1 & iter_no > (iter - n)])\n",
    "    }else{\n",
    "        data.table()\n",
    "    }\n",
    "          \n",
    "    imp_history = rbind(imp_history, data.table(iter_no = iter\n",
    "                                                ,iteration_imp\n",
    "                                                ,cm_mean = as.numeric(NA)))\n",
    "    imp_history[, cm_mean := mean(value),.(feature)]\n",
    "    \n",
    "    return(imp_history[iter_no == iter])\n",
    "    \n",
    "}\n",
    "\n",
    "#importance_data = rbind(importance_data, get_importance_data(model,1,TRUE,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importance_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in each iteration the result of this function is checked\n",
    "#importance data should hold historic data for an seed-rep combination through iterations\n",
    "importance_partition = function(grid_partition, iteration_importance_data, column_name) {\n",
    "    # name of the column which grid separation performed will be based on\n",
    "    iteration_importance_data[, `:=`(grid_no, as.numeric(NA))]\n",
    "    iteration_importance_data[get(column_name) < 0, `:=`(grid_no, 0)]\n",
    "    \n",
    "    grid = 0\n",
    "    order = 0\n",
    "    \n",
    "    while (is.na(iteration_importance_data[which.max(iteration_importance_data[[column_name]])]$grid_no)) {\n",
    "        order = order + 1\n",
    "        \n",
    "        grid_up = grid + grid_partition\n",
    "        \n",
    "        idx = which(iteration_importance_data[[column_name]] < grid_up & iteration_importance_data[[column_name]] > grid)       \n",
    "        iteration_importance_data[idx, `:=`(grid_no, order)]        \n",
    "        grid = copy(grid_up)       \n",
    "    }\n",
    "    iteration_importance_data[order(grid_no), `:=`(grid_order, .GRP), .(grid_no)]\n",
    "    \n",
    "    return(iteration_importance_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start_elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_elimination = function(importance_data_partioned){\n",
    "    #partitioned_importance_data\n",
    "    importance_data_partioned = importance_data_partioned[order(iter_no)]\n",
    "    importance_data_partioned[,prev_grid_order := shift(grid_order,1, type = \"lag\"),.(feature)]\n",
    "    importance_data_partioned[,order_diff :=  grid_order - prev_grid_order ]\n",
    "\n",
    "    elimination_start_iter = ifelse(nrow(importance_data_partioned[order_diff == 0,.N,.(iter_no)][N == length(feature_names)]) > 0,\n",
    "                                   importance_data_partioned[order_diff == 0,.N,.(iter_no)][N == length(feature_names)]$iter_no,\n",
    "                                   0)\n",
    "    return(elimination_start_iter)\n",
    "}\n",
    "# returns the iteration number where the elimination starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature_elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_elimination <- function(h, total_numof_eliminated_vars, ranked_features) {\n",
    "    numof_columns_left = length(ranked_features) - (total_numof_eliminated_vars + h)\n",
    "    columns_left = ranked_features[1:numof_columns_left]\n",
    "    \n",
    "    eliminated_columns = setdiff((length(ranked_features) - total_numof_eliminated_vars),numof_columns_left)\n",
    "    eliminated_columns = ranked_features[eliminated_columns]\n",
    "    \n",
    "    # update total_numof_eliminated_vars\n",
    "    total_numof_eliminated_vars = length(ranked_features) - length(columns_left)\n",
    "    \n",
    "    return(list(columns_left, total_numof_eliminated_vars, h, eliminated_columns))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## refresh_sample_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_sample_pool <- function(selected.seed) {\n",
    "    set.seed(selected.seed)\n",
    "        \n",
    "    unlabeled_pool = as.data.table(maximinLHS(n = unlabeled_ins, k = nofparams, dup = 5))\n",
    "    \n",
    "    if(model.type == \"basic\"){\n",
    "        unlabeled_pool$V1 = qunif(unlabeled_pool$V1, 10, 90) \n",
    "        unlabeled_pool$V2 = qunif(unlabeled_pool$V2, 10, 90)   \n",
    "     }else if(model.type != \"basic\"){   \n",
    "        unlabeled_pool$V1 = qunif(unlabeled_pool$V1, 10, 90) \n",
    "        unlabeled_pool$V2 = qunif(unlabeled_pool$V2, 10, 90)\n",
    "        unlabeled_pool$V3 = qunif(unlabeled_pool$V3, 1, 10) \n",
    "        unlabeled_pool$V4 = qunif(unlabeled_pool$V4, 0.01, 1)    \n",
    "        unlabeled_pool$V5 = qunif(unlabeled_pool$V5, 0.00001, 0.0001) \n",
    "        unlabeled_pool$V6 = qunif(unlabeled_pool$V6, 90, 110)  \n",
    "    }  \n",
    "    setnames(unlabeled_pool, c(paste0(\"V\",1:nofparams)), feature_names)\n",
    "    \n",
    "return(unlabeled_pool)       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_training_set <- function(model.type,seed.list,data.size){\n",
    "    training_set_all = data.table()\n",
    "    for( i in seed.list){\n",
    "        training_set.name= paste0(data.path,\"training_set\",\"_\",model.type,\"_\",data.size,\"_seed\",i,\".csv\")\n",
    "        training_set <- fread(training_set.name) \n",
    "    \n",
    "        training_set_all = rbind(training_set_all,data.table(training_set, \"seed\" = i))\n",
    "        rm(training_set,training_set.name)  \n",
    "        }\n",
    "   return(training_set_all)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write_importance.rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_importance.rf = function(seed,rep,iter,model,sample.type){\n",
    "    importance_table = data.table()\n",
    "    importance_table = rbind(importance_table, data.table(seed = seed, rep = rep, iter_no = iter\n",
    "                                                      , scaled = \"yes\", type = \"1\",\n",
    "                                                      t(importance(model,type=1,scaled = TRUE)))\n",
    "                            , use.names = FALSE)\n",
    "    importance_table = rbind(importance_table, data.table(seed = seed, rep = rep, iter_no = iter\n",
    "                                                  , scaled = \"yes\", type = \"2\",\n",
    "                                                  t(importance(model,type=2,scaled = TRUE)))\n",
    "                            , use.names = FALSE)\n",
    "    importance_table = rbind(importance_table, data.table(seed = seed, rep = rep, iter_no = iter\n",
    "                                                  , scaled = \"no\", type = \"1\",\n",
    "                                                  t(importance(model,type=1,scaled = FALSE)))\n",
    "                            , use.names = FALSE)\n",
    "    importance_table = rbind(importance_table, data.table(seed = seed, rep = rep, iter_no = iter\n",
    "                                                  , scaled = \"no\", type = \"2\",\n",
    "                                                  t(importance(model,type=2,scaled = FALSE)))\n",
    "                            , use.names = FALSE)\n",
    "    \n",
    "    importance_table = melt(importance_table, id.vars = c(\"seed\",\"rep\",\"iter_no\",\"scaled\",\"type\")\n",
    "                           , measure.vars = colnames(importance_table[,.SD,.SDcols = -c(\"seed\",\"rep\",\"iter_no\",\"scaled\",\"type\")]))\n",
    "    setnames(importance_table,c(\"variable\"),c(\"feature\"))\n",
    "    \n",
    "    fwrite(importance_table,paste0(outputs.path,model.type,\"_importance_table_\",sample.type,\".csv\"), append = TRUE)\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.6",
   "language": "R",
   "name": "ir36"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "80.9983px",
    "width": "167.995px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320.135px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
