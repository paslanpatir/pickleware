{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder.path = \"C:/Users/paslanpatir/Desktop/TEZ_v2/\"\n",
    "source(paste0(folder.path,\"pickleware/pickleware/TezV2_SetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"C:/Program Files/NetLogo 6.0.4/app\"\n",
    "folder.path = \"C:/Users/paslanpatir/Desktop/TEZ_v2/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "data.path = paste0(folder.path,\"data/\")\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V2_StaticElim_PoolUpd_\",model.type,\"_\",Sys.Date())\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters ####\n",
    "## Set model parameters Number of replications for each instance\n",
    "nofrep = 10\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "if (model.type == \"basic\") {\n",
    "    feature_names = c(\"density\", \"%-similar-wanted\")\n",
    "} else if (model.type == \"dummy\") {\n",
    "    feature_names = c(\"density\", \"%-similar-wanted\", \"budget-multiplier-dummy\", \"density-multiplier-dummy\", \n",
    "        \"noise-dummy\", \"tick-limit\")\n",
    "}  \n",
    "# \n",
    "output_name = c(\"percent-similar\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "mtry = 2\n",
    "nperm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 11\n",
    "metarep = c(1:5)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 100\n",
    "test_ins = c(100)\n",
    "train_ins_oneshot = 100\n",
    "train_ins_Ad = 50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameters\n",
    "h <- 1  # number of variables eliminated in each step\n",
    "\n",
    "seed.focus = c(0,4)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "sample.type = \"\"\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "feature_ranges =data.table(  feature = feature_names\n",
    "                           , min_range = c(10,10,1,0.01,0.00001,90)\n",
    "                           , max_range = c(90,90,10,1,0.0001,110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_sample_pool_Elim <- function(selected.seed, columns_left = feature_names) {\n",
    "    set.seed(selected.seed)\n",
    "    \n",
    "    \n",
    "    unlabeled_pool = as.data.table(maximinLHS(n = unlabeled_ins, k = length(columns_left), dup = 5))\n",
    "    setnames(unlabeled_pool, c(paste0(\"V\",1:length(columns_left))), columns_left)\n",
    "        \n",
    "     \n",
    "    for( c in 1:length(columns_left)){\n",
    "      unlabeled_pool[[c]] = qunif(unlabeled_pool[[c]],feature_ranges[feature == colnames(unlabeled_pool)[c]]$min_range\n",
    "                                                     ,feature_ranges[feature == colnames(unlabeled_pool)[c]]$max_range)\n",
    "    }\n",
    "    \n",
    "    random_pool_all= data.table()\n",
    "    eliminated_columns = setdiff(feature_names,columns_left)\n",
    "    if(length(eliminated_columns) > 0){\n",
    "        for( e in 1:length(eliminated_columns)){\n",
    "            random_pool = data.table(runif(unlabeled_ins\n",
    "                                    ,feature_ranges[feature == eliminated_columns[e]]$min_range\n",
    "                                    ,feature_ranges[feature == eliminated_columns[e]]$max_range) )\n",
    "            setnames(random_pool,eliminated_columns[e])\n",
    "            \n",
    "            random_pool_all= cbind(random_pool_all,random_pool)\n",
    "        }\n",
    "    \n",
    "   unlabeled_pool = cbind(unlabeled_pool,random_pool_all)     \n",
    "}\n",
    "    \n",
    "return(unlabeled_pool)       \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "for( t in test_ins){\n",
    "    test_set.name= paste0(data.path,\"test_set\",\"_\",model.type,\"_\",t,\".csv\")\n",
    "    test_set <- fread(test_set.name)  \n",
    "    \n",
    "    assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,seed.focus,train_ins_Ad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on strategy:\n",
    "\n",
    "#Eliminate at the end\n",
    "if (model.type == \"basic\") {\n",
    "    sample_selection_iteration_order = c(1:(iteration_budget - 1))\n",
    "    feature_elimination_iteration_order = c(iteration_budget - 1)\n",
    "} else if (model.type == \"dummy\") {\n",
    "    sample_selection_iteration_order = c(1:(iteration_budget - 1))\n",
    "    feature_elimination_iteration_order = c((iteration_budget - 4):(iteration_budget - 1))\n",
    "    feature_elimination_iteration_order = feature_elimination_iteration_order[feature_elimination_iteration_order > 0] # eliminate negative order\n",
    "}\n",
    "elimination_freq_schedule = c(rep(0,(iteration_budget-5)),rep(1,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adaptive Feature Selection Training ####\n",
    "\n",
    "# Record model performances\n",
    "performance_table = data.table(iter = numeric(),seed = numeric(),rep = numeric(),size = numeric(), mae = numeric(), rmse = numeric(), mape = numeric())\n",
    "# Record obb_error table\n",
    "obb_error = data.table(iter = numeric() ,obb_error = numeric(),seed = numeric(),rep = numeric())\n",
    "\n",
    "## initialize variables\n",
    "predictedLabels_all = data.table()\n",
    "train_candidates_all = data.table()\n",
    "training_set_Ad_final = data.table()\n",
    "importance_table_AdFe_All = data.table()\n",
    "iteration_history_AdFe = data.table()\n",
    "\n",
    "\n",
    "# specify variables(columns) to be used initialize\n",
    "columns_left = feature_names\n",
    "total_numof_eliminated_vars <- 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){\n",
    "\n",
    "print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))\n",
    "    \n",
    "for (r in metarep){ #replications\n",
    "    set.seed(i + r)\n",
    "        print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "    \n",
    "    training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "    train_candidates_table = data.table()\n",
    "        \n",
    "    columns_left = feature_names # reset at the beginning of each iteration\n",
    "    total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "    \n",
    "    iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer(), \"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical())\n",
    "\n",
    "    iter = 1\n",
    "    while(iter <= iteration_budget){   \n",
    "        print(iter)\n",
    "    \n",
    "        trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "        trainy = training_set_Ad$output\n",
    "        \n",
    "        # Train the model\n",
    "        model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE,ntree = ntree, mtry = mtry, nperm = nperm)\n",
    "        model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "        assign(model_Sub.name,model_Sub)\n",
    "        model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "        saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "        if (length(columns_left) == length(feature_names)) {\n",
    "        ranked_features = get_variable_importance(model_Sub)\n",
    "        }\n",
    "        \n",
    "        #to append\n",
    "        obb_err = rbind( data.table(iter = numeric() ,obb_error = numeric(),seed = numeric(),rep = numeric())\n",
    "                        ,data.table(iter, obb_error_func(model_Sub), i, r), use.names = FALSE)            \n",
    "        fwrite(obb_err,paste0(outputs.path,sample.folder,model.type,\"_Append_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        ##                \n",
    "        obb_error = rbind(obb_error,data.table(iter,obb_error_func(model_Sub),i,r),use.names=FALSE)\n",
    "        \n",
    "        # test the model on test set\n",
    "        predictedLabels_Comb = data.table()\n",
    "        for (t in test_ins) {\n",
    "            test_set = get(paste0(\"test_set_\", t))\n",
    "            \n",
    "            test_predictions_Sub = get_test_predictions(model_Sub, test_set,error_type)\n",
    "            predictedLabels_Sub = test_predictions_Sub[[1]]\n",
    "            setnames(predictedLabels_Sub, c(\"pred_output\", error_type), c(paste0(\"pred_output_\", iter), paste0(error_type, \"_\", iter)))\n",
    "\n",
    "            fwrite(predictedLabels_Sub\n",
    "                   ,paste0(outputs.path,PL.folder,model.type\n",
    "                           ,\"_\",\"predictedLabels.\",sample.type,\"_seed_\",i,\"_iter_\",iter,\"_rep_\",r,\"_size_\",t,\".csv\") ) \n",
    "\n",
    "            predictedLabels_Comb = rbind(predictedLabels_Comb, data.table(size = t,predictedLabels_Sub))   \n",
    "             \n",
    "             # Keep test set error records\n",
    "                #to append\n",
    "                perf_table = rbind(data.table(iter = numeric(),seed = numeric(),rep = numeric(),size = numeric(), mae = numeric(), rmse = numeric(), mape = numeric())\n",
    "                                  ,data.table(iter, i, r, t, test_predictions_Sub[[2]]),use.names = FALSE )\n",
    "                fwrite(perf_table,paste0(outputs.path,sample.folder,model.type,\"_Append_\",\"performance_table_\",sample.type,\".csv\"),append = TRUE )    \n",
    "                ##\n",
    "                performance_table = rbind(performance_table, data.table(iter, i, r, t, test_predictions_Sub[[2]]),use.names = FALSE)\n",
    "                        }\n",
    "        if(iter == 1){\n",
    "            predictedLabels_table = copy(predictedLabels_Comb[,1:4])\n",
    "        }\n",
    "            \n",
    "        predictedLabels_table = cbind(predictedLabels_table, predictedLabels_Comb[,.SD ,.SDcols = c(paste0(\"pred_output_\", iter), paste0(error_type, \"_\", iter))])\n",
    "\n",
    "        write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "        if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0), use.names = FALSE)\n",
    "            \n",
    "            if (iter %in% sample_selection_iteration_order) { # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool_Elim(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub)\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "          \n",
    "                # add labeled candidates to the train data\n",
    "                training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")])\n",
    "                \n",
    "                # update iteration_history\n",
    "                 iteration_history[iter]$IsDataSelected= 1\n",
    "                }\n",
    "            \n",
    "            elimination_freq = 1\n",
    "            while(elimination_freq <= elimination_freq_schedule[iter]) {\n",
    "               if (iter %in% feature_elimination_iteration_order) { # feature elimination module\n",
    "\n",
    "                    feature_elimination_result = feature_elimination(h, total_numof_eliminated_vars, ranked_features)\n",
    "\n",
    "                    columns_left = feature_elimination_result[[1]]  # \n",
    "                    eliminated_columns = feature_elimination_result[[4]]  #   not necessary\n",
    "                    total_numof_eliminated_vars = as.numeric(feature_elimination_result[2])\n",
    "                    numof_eliminated_vars = as.numeric(feature_elimination_result[3])  #   not necessary \n",
    "\n",
    "                    # update iteration_history\n",
    "                    iteration_history[iter]$IsFeatureEliminated= 1\n",
    "               }\n",
    "               elimination_freq = elimination_freq + 1\n",
    "           }\n",
    "        }\n",
    "        fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "        iter = iter + 1\n",
    "    }\n",
    "    fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "    fwrite(data.table(predictedLabels_table, \"seed\" = i, \"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_predictedLabels_table_\",sample.type,\".csv\"),append = TRUE )                                       \n",
    "    \n",
    "    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "}\n",
    "    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final records\n",
    "#FinalTrainData_AdFe = copy(training_set_Ad_final)\n",
    "obb_error_AdFe = copy(obb_error)\n",
    "performance_table_AdFe = copy(performance_table)\n",
    "#predictedLabels_table_AdFe = copy(predictedLabels_all)\n",
    "#train_candidates_table_AdFe  = copy(train_candidates_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(training_set_Ad_final,obb_error,performance_table,predictedLabels_all,train_candidates_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fwrite(importance_table_AdFe_All,paste0(outputs.path,model.type,\"_\",\"importance_table_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "#fwrite(FinalTrainData_AdFe,paste0(outputs.path,model.type,\"_\",\"FinalTrainData_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "fwrite(performance_table_AdFe,paste0(outputs.path,sample.folder,model.type,\"_\",\"performance_table_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "#fwrite(train_candidates_table_AdFe,paste0(outputs.path,model.type,\"_\",\"train_candidates_table_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "#fwrite(predictedLabels_table_AdFe,paste0(outputs.path,model.type,\"_\",\"predictedLabels_table_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "fwrite(obb_error_AdFe,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_AdFe\",\"_\",selection_metric,\".csv\") )\n",
    "#fwrite(iteration_history_AdFe,paste0(outputs.path,model.type,\"_\",\"iteration_history_AdFe\",\"_\",selection_metric,\".csv\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(importance_table_AdFe,FinalTrainData_AdFe,iteration_history_AdFe,performance_table_AdFe,train_candidates_table_AdFe,predictedLabels_table_AdFe,obb_error_AdFe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)\n",
    "#NLQuit(all=TRUE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.6",
   "language": "R",
   "name": "ir36"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "80.9983px",
    "width": "167.995px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320.125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
